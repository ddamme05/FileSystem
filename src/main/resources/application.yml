spring:
  application:
    name: file-system
  servlet:
    multipart:
      enabled: true
      max-file-size: 10MB
      max-request-size: 10MB
      file-size-threshold: 1KB

  datasource:
    url: ${SPRING_DATASOURCE_URL:jdbc:postgresql://localhost:5433/file_system_db}
    username: ${SPRING_DATASOURCE_USERNAME:user}
    password: ${SPRING_DATASOURCE_PASSWORD:password}
    driver-class-name: org.postgresql.Driver
    hikari:
      maximum-pool-size: 10
      minimum-idle: 2
      connection-timeout: 5000
      idle-timeout: 300000
      max-lifetime: 600000

  jpa:
    hibernate:
      ddl-auto: none  # Flyway owns DDL - Hibernate only validates
    open-in-view: false
    show-sql: false
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true

  flyway:
    enabled: true
    baseline-on-migrate: true
    clean-disabled: true
    out-of-order: true

server:
  port: ${SERVER_PORT:8080}

management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus
  endpoint:
    health:
      probes:
        enabled: true


  metrics:
    export:
      otlp:
        enabled: true
        url: ${MANAGEMENT_OTLP_METRICS_EXPORT_URL:http://datadog:4318/v1/metrics}
        step: ${MANAGEMENT_OTLP_METRICS_EXPORT_STEP:10s}
    tags:
      application: ${spring.application.name}
      service: ${DD_SERVICE:file-system-app}
      env: ${DD_ENV:dev}
      version: ${DD_VERSION:1.0.0}
      region: ${AWS_REGION:us-east-1}
    distribution:
      percentiles-histogram:
        http.server.requests: true

aws:
  region: ${AWS_REGION:us-east-1}
  s3:
    bucket-name: ${AWS_S3_BUCKET:filesystem-s3}
    presign-ttl-minutes: ${AWS_S3_PRESIGN_TTL_MINUTES:5}

metrics:
  s3:
    health:
      enabled: true
      period: 300000

security:
  jwt:
    secret: "${SECURITY_JWT_SECRET:IkZTI0VwjSvZuMo99cXAx9xzeJhKHLyJODC5PoHsjO4=}"
    expiration-ms: ${SECURITY_JWT_EXPIRATION_MS:7200000}
    issuer: ${JWT_ISSUER:file-system}
    clock-skew-seconds: ${SECURITY_JWT_CLOCK_SKEW_SECONDS:30}
  ratelimit:
    per-minute:
      upload: 10
      download: 120
      login: 10
    message: "Please slow down"
    send-retry-after: true
    retry-after: 30s
  cors:
    allowed-origins:
      - http://localhost:3000
      - http://127.0.0.1:3000
      - http://localhost:5173
      - http://127.0.0.1:5173
    allowed-methods:
      - GET
      - POST
      - PUT
      - PATCH
      - DELETE
      - OPTIONS
      - HEAD
    allowed-headers:
      - Authorization
      - Content-Type
      - X-Request-ID
      - Accept
    exposed-headers:
      - X-Request-ID
      - Content-Disposition
      - Location
      - X-Has-Text
      - X-Text-Length
      - ETag
    allow-credentials: true

logging:
  level:
    software.amazon.awssdk: INFO  # Set to DEBUG locally if needed; INFO in prod to reduce noise
    org.ddamme: INFO  # INFO in prod, override to DEBUG locally via profile

# AI Worker Configuration
ai:
  worker:
    enabled: ${AI_WORKER_ENABLED:true}
    core-threads: 2  # Tuned for t3.medium (2 vCPU)
    max-threads: 4   # 2x core for burst capacity
    queue-capacity: 100
    batch-size: 10
    poll-interval: 5000  # 5 seconds
    reclaim-interval: 60000  # 1 minute
    stale-job-timeout: PT15M  # 15 minutes (ISO-8601 duration)
    max-attempts: 3  # Retry failed jobs up to N times before DLQ
    ocr:
      max-pages: 50  # Cost control for large PDFs
      language: eng  # Tesseract language (eng, fra, deu, spa, etc.)
      data-path: ${TESSDATA_PREFIX:/usr/share/tesseract-ocr/5/tessdata}
      auto-create: ${AI_OCR_AUTO_CREATE:true}
      file-types:
        - application/pdf
        - image/*
  ocr:
    reconciler:
      enabled: true  # Can backfill even when workers paused
      cron: "0 15 * * * *"  # Every hour at :15
      lookback-days: 30  # Only backfill files from last N days

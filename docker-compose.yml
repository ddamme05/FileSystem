name: file-system

secrets:
  dd_api_key:
    file: ./.secrets/dd_api_key
  dd_site:
    file: ./.secrets/dd_site
  db_password:
    file: ./.secrets/db_password
  jwt_secret:
    file: ./.secrets/jwt_secret


services:
  postgres-db:
    image: postgres:17-alpine
    restart: unless-stopped
    ports: [ "5433:5432" ]
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
      POSTGRES_DB: file_system_db
    secrets: [ db_password ]
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U user -d file_system_db -q" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  app:
    build: .
    image: file-system-app:local
    restart: unless-stopped
    depends_on:
      postgres-db:
        condition: service_healthy
    ports: [ "8080:8080" ]
    read_only: true
    tmpfs: [ "/tmp","/var/tmp" ]
    cap_drop: [ ALL ]
    cap_add: [ SETUID, SETGID ]
    security_opt: [ "no-new-privileges:true" ]
    init: true
    environment:
      # Datadog
      JAVA_TOOL_OPTIONS: "-javaagent:/app/dd-java-agent.jar ${JAVA_TOOL_OPTIONS:-} -XX:MaxRAMPercentage=75.0"
      DD_AGENT_HOST: datadog
      DD_SERVICE: file-system-app
      DD_ENV: dev
      DD_VERSION: "1.0.0"
      DD_LOGS_INJECTION: "true"
      DD_PROFILING_ENABLED: "true"
      DD_RUNTIME_METRICS_ENABLED: "true"
      DD_JMXFETCH_ENABLED: "false"
      DD_TRACE_SAMPLE_RATE: "1.0"
      DD_TAGS: "team:learning,tier:backend"
      MANAGEMENT_OTLP_METRICS_EXPORT_URL: "http://datadog:4318/v1/metrics"
      MANAGEMENT_ENDPOINT_HEALTH_PROBES_ENABLED: "true"
      MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE: "health,info,prometheus"

      # DB
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres-db:5432/file_system_db
      SPRING_DATASOURCE_USERNAME: user
      SPRING_PROFILES_ACTIVE: dev

      # AWS Config
      # For local dev: uses ~/.aws credentials (mounted below)
      # For EC2: Remove AWS_PROFILE, AWS_EC2_METADATA_DISABLED, and volumes; use IAM role instead
      # If using EC2 IAM role and containers can't assume it, set IMDS hop limit: 
      #   aws ec2 modify-instance-metadata-options --instance-id <ID> --http-put-response-hop-limit 2
      AWS_REGION: us-east-1
      AWS_S3_BUCKET: ${AWS_S3_BUCKET:-filesystem-s3}
      AWS_PROFILE: file-system-app-role
      AWS_SHARED_CREDENTIALS_FILE: /aws/credentials
      AWS_CONFIG_FILE: /aws/config
      AWS_SDK_LOAD_CONFIG: "true"
      AWS_EC2_METADATA_DISABLED: "true"  # Remove this on EC2 to use IAM role
    volumes:
      - ${HOME}/.aws:/aws:ro  # Remove this on EC2 to use IAM role
    secrets: [ db_password, jwt_secret ]
    healthcheck:
      test: [ "CMD-SHELL", "curl -fsS http://localhost:8080/actuator/health | grep -q '\"status\":\"UP\"' || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      com.datadoghq.ad.logs: '[{"source":"java","service":"file-system-app"}]'

  frontend:
    build:
      context: ./client
      dockerfile: Dockerfile
    image: file-system-frontend:local
    restart: unless-stopped
    depends_on:
      app:
        condition: service_healthy
    ports:
      - "3000:80"  # Dev: host:3000, Prod: change to "80:80" for direct HTTP access
    # Note: Not using user: "101:101" because tmpfs mounts need root to set permissions
    # Nginx drops privileges internally to nginx user for worker processes
    cap_drop: [ ALL ]
    cap_add: [ NET_BIND_SERVICE, CHOWN, SETUID, SETGID ]  # Needed for nginx to drop privileges
    security_opt: [ "no-new-privileges:true" ]
    init: true
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost/health" ]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      com.datadoghq.ad.logs: '[{"source":"nginx","service":"file-system-frontend"}]'

  datadog:
    image: gcr.io/datadoghq/agent:7
    restart: unless-stopped
    entrypoint: [ "/bin/sh","-lc" ]
    command:
      - >
        export DD_API_KEY="$(tr -d '\r\n' < /run/secrets/dd_api_key)";
        export DD_SITE="$(tr -d '\r\n' < /run/secrets/dd_site)";
        exec /init
    environment:
      DD_ENV: dev
      DD_APM_ENABLED: "true"
      DD_APM_NON_LOCAL_TRAFFIC: "true"
      DD_LOGS_ENABLED: "true"
      DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL: "true"
      DD_CONTAINER_EXCLUDE_LOGS: "name:datadog-agent"
      DD_DOCKER_LABELS_AS_TAGS: '{"com.docker.compose.service":"service","com.docker.compose.project":"project"}'
      DD_PROCESS_AGENT_ENABLED: "false"
      DD_OTLP_CONFIG_RECEIVER_PROTOCOLS_GRPC_ENDPOINT: "0.0.0.0:4317"
      DD_OTLP_CONFIG_RECEIVER_PROTOCOLS_HTTP_ENDPOINT: "0.0.0.0:4318"
      DD_OTLP_CONFIG_METRICS_ENABLED: "true"
      DD_OTLP_CONFIG_TRACES_ENABLED: "true"
    secrets: [ dd_api_key, dd_site ]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /proc/:/host/proc/:ro
      - /sys/fs/cgroup:/host/sys/fs/cgroup:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    ports: [ "8126:8126","4317:4317","4318:4318" ]

volumes:
  postgres-data:
